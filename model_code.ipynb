{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported successfully ðŸ•º\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import json\n",
    "\n",
    "print('All modules imported successfully ðŸ•º')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../one/dataset/Sarcasm_Headlines_Dataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = open('../one/dataset/Sarcasm_Headlines_Dataset.json','r').readlines()\n",
    "data = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in contents:\n",
    "    data.append(json.loads(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article_link': 'https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5',\n",
       " 'headline': \"former versace store clerk sues over secret 'black code' for minority shoppers\",\n",
       " 'is_sarcastic': 0}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "labels = []\n",
    "urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in data:\n",
    "    sentences.append(x['headline'])\n",
    "    labels.append(x['is_sarcastic'])\n",
    "    urls.append(x['article_link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000,oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "padded = pad_sequences(sequences=sequences, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 308,    1,  679, 3337, 2298,   48,  382, 2576,    1,    6, 2577,\n",
       "       8434,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26709"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(26709, 40)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(labels))\n",
    "display(padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for x in sentences:\n",
    "    lengths.append(len(x))\n",
    "\n",
    "max_length = int(np.median(np.array(lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = sentences[:training_data]\n",
    "test_sentences = sentences[training_data:]\n",
    "train_labels = labels[:training_data]\n",
    "test_labels = labels[training_data:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, \n",
    "                                padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_padded = tf.constant(training_padded)\n",
    "train_labels = tf.constant(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, \n",
    "                                padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_padded = tf.constant(testing_padded)\n",
    "test_labels = tf.constant(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(10000, 16, input_length=max_length),\n",
    "    keras.layers.GlobalAveragePooling1D(),\n",
    "    keras.layers.Dense(24, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "625/625 - 2s - loss: 0.6393 - accuracy: 0.6120 - val_loss: 0.5062 - val_accuracy: 0.8037 - 2s/epoch - 3ms/step\n",
      "Epoch 2/30\n",
      "625/625 - 1s - loss: 0.3795 - accuracy: 0.8540 - val_loss: 0.3619 - val_accuracy: 0.8518 - 1s/epoch - 2ms/step\n",
      "Epoch 3/30\n",
      "625/625 - 2s - loss: 0.2766 - accuracy: 0.8923 - val_loss: 0.3433 - val_accuracy: 0.8580 - 2s/epoch - 3ms/step\n",
      "Epoch 4/30\n",
      "625/625 - 2s - loss: 0.2250 - accuracy: 0.9144 - val_loss: 0.3422 - val_accuracy: 0.8568 - 2s/epoch - 3ms/step\n",
      "Epoch 5/30\n",
      "625/625 - 1s - loss: 0.1921 - accuracy: 0.9280 - val_loss: 0.3550 - val_accuracy: 0.8556 - 1s/epoch - 2ms/step\n",
      "Epoch 6/30\n",
      "625/625 - 1s - loss: 0.1672 - accuracy: 0.9380 - val_loss: 0.3768 - val_accuracy: 0.8514 - 1s/epoch - 2ms/step\n",
      "Epoch 7/30\n",
      "625/625 - 1s - loss: 0.1463 - accuracy: 0.9466 - val_loss: 0.3903 - val_accuracy: 0.8547 - 1s/epoch - 2ms/step\n",
      "Epoch 8/30\n",
      "625/625 - 1s - loss: 0.1299 - accuracy: 0.9538 - val_loss: 0.4149 - val_accuracy: 0.8517 - 1s/epoch - 2ms/step\n",
      "Epoch 9/30\n",
      "625/625 - 2s - loss: 0.1161 - accuracy: 0.9612 - val_loss: 0.4557 - val_accuracy: 0.8465 - 2s/epoch - 3ms/step\n",
      "Epoch 10/30\n",
      "625/625 - 1s - loss: 0.1032 - accuracy: 0.9653 - val_loss: 0.4758 - val_accuracy: 0.8445 - 1s/epoch - 2ms/step\n",
      "Epoch 11/30\n",
      "625/625 - 1s - loss: 0.0923 - accuracy: 0.9693 - val_loss: 0.5274 - val_accuracy: 0.8389 - 1s/epoch - 2ms/step\n",
      "Epoch 12/30\n",
      "625/625 - 2s - loss: 0.0841 - accuracy: 0.9721 - val_loss: 0.5769 - val_accuracy: 0.8343 - 2s/epoch - 3ms/step\n",
      "Epoch 13/30\n",
      "625/625 - 1s - loss: 0.0760 - accuracy: 0.9756 - val_loss: 0.5831 - val_accuracy: 0.8338 - 1s/epoch - 2ms/step\n",
      "Epoch 14/30\n",
      "625/625 - 1s - loss: 0.0690 - accuracy: 0.9782 - val_loss: 0.6497 - val_accuracy: 0.8305 - 1s/epoch - 2ms/step\n",
      "Epoch 15/30\n",
      "625/625 - 1s - loss: 0.0615 - accuracy: 0.9812 - val_loss: 0.6713 - val_accuracy: 0.8314 - 1s/epoch - 2ms/step\n",
      "Epoch 16/30\n",
      "625/625 - 1s - loss: 0.0548 - accuracy: 0.9840 - val_loss: 0.7054 - val_accuracy: 0.8253 - 1s/epoch - 2ms/step\n",
      "Epoch 17/30\n",
      "625/625 - 1s - loss: 0.0515 - accuracy: 0.9843 - val_loss: 0.7501 - val_accuracy: 0.8217 - 1s/epoch - 2ms/step\n",
      "Epoch 18/30\n",
      "625/625 - 1s - loss: 0.0477 - accuracy: 0.9854 - val_loss: 0.8070 - val_accuracy: 0.8247 - 1s/epoch - 2ms/step\n",
      "Epoch 19/30\n",
      "625/625 - 1s - loss: 0.0423 - accuracy: 0.9873 - val_loss: 0.8473 - val_accuracy: 0.8229 - 1s/epoch - 2ms/step\n",
      "Epoch 20/30\n",
      "625/625 - 1s - loss: 0.0392 - accuracy: 0.9887 - val_loss: 0.9010 - val_accuracy: 0.8196 - 1s/epoch - 2ms/step\n",
      "Epoch 21/30\n",
      "625/625 - 1s - loss: 0.0342 - accuracy: 0.9904 - val_loss: 0.9657 - val_accuracy: 0.8198 - 1s/epoch - 2ms/step\n",
      "Epoch 22/30\n",
      "625/625 - 1s - loss: 0.0312 - accuracy: 0.9909 - val_loss: 0.9780 - val_accuracy: 0.8153 - 1s/epoch - 2ms/step\n",
      "Epoch 23/30\n",
      "625/625 - 1s - loss: 0.0284 - accuracy: 0.9921 - val_loss: 1.0500 - val_accuracy: 0.8159 - 1s/epoch - 2ms/step\n",
      "Epoch 24/30\n",
      "625/625 - 1s - loss: 0.0259 - accuracy: 0.9923 - val_loss: 1.0871 - val_accuracy: 0.8125 - 1s/epoch - 2ms/step\n",
      "Epoch 25/30\n",
      "625/625 - 2s - loss: 0.0257 - accuracy: 0.9924 - val_loss: 1.1463 - val_accuracy: 0.8119 - 2s/epoch - 2ms/step\n",
      "Epoch 26/30\n",
      "625/625 - 2s - loss: 0.0219 - accuracy: 0.9941 - val_loss: 1.2126 - val_accuracy: 0.8135 - 2s/epoch - 2ms/step\n",
      "Epoch 27/30\n",
      "625/625 - 1s - loss: 0.0190 - accuracy: 0.9953 - val_loss: 1.2432 - val_accuracy: 0.8106 - 1s/epoch - 2ms/step\n",
      "Epoch 28/30\n",
      "625/625 - 1s - loss: 0.0184 - accuracy: 0.9948 - val_loss: 1.2831 - val_accuracy: 0.8071 - 1s/epoch - 2ms/step\n",
      "Epoch 29/30\n",
      "625/625 - 1s - loss: 0.0174 - accuracy: 0.9954 - val_loss: 1.3258 - val_accuracy: 0.8049 - 1s/epoch - 2ms/step\n",
      "Epoch 30/30\n",
      "625/625 - 1s - loss: 0.0146 - accuracy: 0.9965 - val_loss: 1.3945 - val_accuracy: 0.8050 - 1s/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_padded,train_labels, epochs=30,\n",
    "            validation_data=(testing_padded,test_labels), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ['this is so dumb that I got enlightened', 'it is a very dry wet day','hi there']\n",
    "sequence = tokenizer.texts_to_sequences(sentence)\n",
    "padded = pad_sequences(sequence, maxlen=max_length,\n",
    "                        padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.4194850e-07],\n",
       "       [9.9938130e-01],\n",
       "       [2.9306263e-02]], dtype=float32)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89d90e86139c8b20d19e8110fb3386ab7fe25194b169c5de31c168141441ed82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
